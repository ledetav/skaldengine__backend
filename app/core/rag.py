import chromadb
from google import genai
from google.genai import types
from chromadb.config import Settings as ChromaSettings
from app.core.config import settings
from app.models.lore_item import LoreItem

client = genai.Client(api_key=settings.GEMINI_API_KEY)

chroma_client = chromadb.PersistentClient(path=settings.CHROMA_DB_PATH)
lore_collection = chroma_client.get_or_create_collection(name="character_lore")

def generate_embedding(text: str) -> list[float]:
    """
    –ü—Ä–µ–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –≤ –≤–µ–∫—Ç–æ—Ä —á–∏—Å–µ–ª —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏ Google gemini-embedding-001.
    """
    try:
        response = client.models.embed_content(
            model="gemini-embedding-001",
            contents=text,
            config=types.EmbedContentConfig(
                task_type="RETRIEVAL_DOCUMENT",
                title="Lore Item" # Title –Ω—É–∂–µ–Ω —Ç–æ–ª—å–∫–æ –¥–ª—è task_type=RETRIEVAL_DOCUMENT
            )
        )
        return response.embeddings[0].values
    except Exception as e:
        print(f"Error generating embedding: {e}")
        return []

def index_lore_item(lore_item: LoreItem):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ñ–∞–∫—Ç –≤ ChromaDB.
    """
    if not lore_item.content:
        return

    embedding = generate_embedding(lore_item.content)
    if not embedding:
        print(f"‚ö†Ô∏è Failed to generate embedding for lore {lore_item.id}")
        return

    lore_collection.upsert(
        ids=[str(lore_item.id)],
        embeddings=[embedding],
        documents=[lore_item.content],
        metadatas=[{
            "character_id": str(lore_item.character_id),
            "category": lore_item.category
        }]
    )
    print(f"‚úÖ Indexed lore item: {lore_item.id}")

def delete_lore_from_index(lore_item_id: str):
    """
    –£–¥–∞–ª—è–µ—Ç —Ñ–∞–∫—Ç –∏–∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã.
    """
    try:
        lore_collection.delete(ids=[lore_item_id])
        print(f"üóëÔ∏è Deleted lore item from index: {lore_item_id}")
    except Exception as e:
        print(f"Error deleting from index: {e}")

def search_relevant_lore(query: str, character_id: str, k: int = 3) -> list[str]:
    """
    –ò—â–µ—Ç —Ç–æ–ø-K —Å–∞–º—ã—Ö –ø–æ—Ö–æ–∂–∏—Ö —Ñ–∞–∫—Ç–æ–≤ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞.
    """
    try:
        # –î–ª—è –∑–∞–ø—Ä–æ—Å–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º task_type="RETRIEVAL_QUERY" –∏ –ù–ï —É–∫–∞–∑—ã–≤–∞–µ–º title
        response = client.models.embed_content(
            model="gemini-embedding-001",
            contents=query,
            config=types.EmbedContentConfig(
                task_type="RETRIEVAL_QUERY"
            )
        )
        query_embedding = response.embeddings[0].values

        results = lore_collection.query(
            query_embeddings=[query_embedding],
            n_results=k,
            where={"character_id": character_id} 
        )

        if results and results['documents']:
            return results['documents'][0] 
        return []
    except Exception as e:
        print(f"Error searching lore: {e}")
        return []