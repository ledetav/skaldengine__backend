import json
import asyncio
import logging
import os
from aiokafka import AIOKafkaConsumer

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("event_logger")

# –í–Ω—É—Ç—Ä–∏ Docker Compose —Å–µ—Ç—å –¥—Ä—É–≥–∞—è, –ø–æ—ç—Ç–æ–º—É –æ–±—Ä–∞—â–∞–µ–º—Å—è –ø–æ –∏–º–µ–Ω–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ "kafka"
KAFKA_BOOTSTRAP_SERVERS = os.getenv("KAFKA_BOOTSTRAP_SERVERS", "skaldenginebackend-kafka:9092")
KAFKA_TOPIC_EVENTS = os.getenv("KAFKA_TOPIC_EVENTS", "skaldenginebackend_entity_events")

async def consume_events():
    consumer = AIOKafkaConsumer(
        KAFKA_TOPIC_EVENTS,
        bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
        group_id="skald-logging-group",
        value_deserializer=lambda m: json.loads(m.decode('utf-8')),
        auto_offset_reset="earliest"
    )
    
    while True:
        try:
            await consumer.start()
            logger.info("üéß Event Logger successfully connected to Kafka!")
            break
        except Exception as e:
            logger.warning(f"‚è≥ Waiting for Kafka to be ready... ({e})")
            await asyncio.sleep(3)
    
    try:
        async for msg in consumer:
            event_data = msg.value
            logger.info("\n" + "="*50)
            logger.info(f"üì• [KAFKA EVENT] Topic: {msg.topic}")
            logger.info(f"üè∑Ô∏è  Event: {event_data.get('event')}")
            logger.info(f"üÜî  Entity ID: {event_data.get('entity_id')}")
            logger.info(f"üì¶  Payload: {json.dumps(event_data.get('payload', {}), indent=2, ensure_ascii=False)}")
            logger.info("="*50 + "\n")
    except asyncio.CancelledError:
        logger.info("üõë Consumer task was cancelled.")
    finally:
        await consumer.stop()

if __name__ == "__main__":
    asyncio.run(consume_events())